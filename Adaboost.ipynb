{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Aprendizagem Computacional 1 - Adaptive Boosting\n",
    "\n",
    "O objetivo deste projeto era encontrar um algoritmo e fazer alteração para tentar melhorar a maneira como o algoritmo classifica um dataset."
   ],
   "id": "7f091ca30c813fee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adaboost: Como funciona?\n",
    "\n",
    "O algoritmo escolhido foi o Adaptive boosting: funciona treinando um modelo base (como uma árvore de decisão) em várias iterações. Em cada iteração, os dados mal classificados ganham mais peso, tornando-se mais importantes na próxima iteração. O modelo final é uma combinação ponderada de todos os modelos treinados, onde cada um contribui com base na sua precisão. Isto resulta num modelo robusto que geralmente tem um desempenho superior aos modelos individuais."
   ],
   "id": "497d0bb8b1a8d35a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Código",
   "id": "1adeb3cd51a52489"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:04:26.773751Z",
     "start_time": "2024-05-19T01:04:26.342236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importing libraries and necessary functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from algorithms.utils_final import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from algorithms.weights_adaboost import *\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from algorithms.weights_adaboost import AdaBoost"
   ],
   "id": "ab74000417da90c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:04:26.971031Z",
     "start_time": "2024-05-19T01:04:26.774892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading the datasets with obter_dataset function\n",
    "list_num_dataset_id = [1464, 1067, 1467, 1504,1494, 1068]\n",
    "dataframes = {}\n",
    "for dataset_id in list_num_dataset_id:\n",
    "    df = obter_dataset(dataset_id)\n",
    "    dataframes[dataset_id] = df"
   ],
   "id": "96294bee8b36a739",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
      "/home/margarida/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:13: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testes\n",
    "\n",
    "Para testar, utilizamos 3 implementações do adaboost:\n",
    "- A primeira é a implementação que fizemos, que é a que temos mais controlo sobre o que acontece.\n",
    "- A segunda é a nossa implementação com a opção de remover outliers.\n",
    "- A terceira é a implementação da biblioteca sklearn.\n",
    "\n",
    "Para cada dataset, corremos os 3 modelos e comparamos os resultados. Decidmos testar com a da biblioteca para perceber quais as diferenças para a implementação que local sem alterações."
   ],
   "id": "1125d8348a757a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:05:21.566789Z",
     "start_time": "2024-05-19T01:04:26.973209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Running the models\n",
    "models = [\n",
    "    (\"AdaBoost ficheiro\", AdaBoost()),\n",
    "    (\"AdaBoost Check Outliers 3\", AdaBoost(check_outliers=True)),\n",
    "    (\"AdaBoost biblioteca\", AdaBoostClassifier(algorithm='SAMME'))\n",
    "]\n",
    "\n",
    "for id in list_num_dataset_id:\n",
    "    print(f\"\\nDataset {id}:\")\n",
    "    X = dataframes[id].drop(columns=['target'], axis=1)\n",
    "    y = dataframes[id]['target']\n",
    "\n",
    "    results = run_cv(X, y, models, means_only=True)"
   ],
   "id": "5e41b5ba4e23c9a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1464:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.7673513513513515\n",
      "\n",
      "\n",
      "Number of outliers identified: 21.3\n",
      "Mean for AdaBoost Check Outliers 3: 0.7686846846846846\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.7833513513513515\n",
      "\n",
      "Dataset 1067:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.8515910629654705\n",
      "\n",
      "\n",
      "Number of outliers identified: 174.1\n",
      "Mean for AdaBoost Check Outliers 3: 0.8397359512525391\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.8473166328142631\n",
      "\n",
      "Dataset 1467:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.9074074074074074\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.9\n",
      "Mean for AdaBoost Check Outliers 3: 0.912962962962963\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.8981481481481483\n",
      "\n",
      "Dataset 1504:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.8536531853026699\n",
      "\n",
      "\n",
      "Number of outliers identified: 315.9\n",
      "Mean for AdaBoost Check Outliers 3: 0.8371927042030134\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.9546576790906689\n",
      "\n",
      "Dataset 1494:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.8426145552560648\n",
      "\n",
      "\n",
      "Number of outliers identified: 303.9\n",
      "Mean for AdaBoost Check Outliers 3: 0.8359928122192273\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.8313117699910151\n",
      "\n",
      "Dataset 1068:\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost ficheiro: 0.9305405405405406\n",
      "\n",
      "\n",
      "Number of outliers identified: 97.6\n",
      "Mean for AdaBoost Check Outliers 3: 0.925143325143325\n",
      "\n",
      "\n",
      "Number of outliers identified: 0.0\n",
      "Mean for AdaBoost biblioteca: 0.9305241605241605\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:05:21.783505Z",
     "start_time": "2024-05-19T01:05:21.567979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "for id in list_num_dataset_id:\n",
    "    n_outliers = showoutliers(id, show_Boxplot=False)\n",
    "    print(f\"\\nDataset {id}:\")\n",
    "    print(f'Número de outliers: {n_outliers}')\n",
    "    print(f'Número de entradas: {len(dataframes[id])}')\n",
    "    #show % of outliers in the dataset\n",
    "    percentage_outliers = n_outliers/(len(dataframes[id]))\n",
    "    print(f'Percentagem de outliers: {percentage_outliers*100:.2f}%')"
   ],
   "id": "e5001e4c911f222e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m \u001B[38;5;129;01min\u001B[39;00m list_num_dataset_id:\n\u001B[0;32m----> 2\u001B[0m     n_outliers \u001B[38;5;241m=\u001B[39m \u001B[43mshowoutliers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_Boxplot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDataset \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mid\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNúmero de outliers: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_outliers\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/Machine_Learning_1/algorithms/utils_final.py:81\u001B[0m, in \u001B[0;36mshowoutliers\u001B[0;34m(ids, show_Boxplot)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshowoutliers\u001B[39m(ids, show_Boxplot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     79\u001B[0m     limite \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m---> 81\u001B[0m     df_1 \u001B[38;5;241m=\u001B[39m \u001B[43mdataframes\u001B[49m[\u001B[38;5;28mid\u001B[39m][dataframes[\u001B[38;5;28mid\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     82\u001B[0m     df_1 \u001B[38;5;241m=\u001B[39m df_1\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     83\u001B[0m     df_not_1 \u001B[38;5;241m=\u001B[39m dataframes[\u001B[38;5;28mid\u001B[39m][dataframes[\u001B[38;5;28mid\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dcda7bbc856e1ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d07f6397dc8ca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
