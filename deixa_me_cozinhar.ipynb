{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import openml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3bb6d46905a224"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def obter_dataset(id):\n",
    "\n",
    "\n",
    "    dataset = openml.datasets.get_dataset(id, download_data=True, download_qualities=True, download_features_meta_data=True)\n",
    "    \n",
    "    X, y, _, attrs = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    df = pd.DataFrame(X, columns=attrs)\n",
    "    df['target'] = y\n",
    "    # converter:\n",
    "    #   0 -> -1\n",
    "    #   1 -> 1\n",
    "    df['target'] = 2*y-1\n",
    "    # erase rows with NaN values\n",
    "    df = df.dropna(how='any', axis=0)\n",
    "\n",
    "    csv_path = f'{id}.csv'\n",
    "    df.to_csv(csv_path, index= False)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e94c12d411fe4c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "list_num_dataset_id = [1464, 1067, 1467, 1504,1494, 1068, 44]\n",
    "dataframes = {}\n",
    "for dataset_id in list_num_dataset_id:\n",
    "    df = obter_dataset(dataset_id)\n",
    "    dataframes[dataset_id] = df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "433bc01e77942d6c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "def run_cv(X,y,algs,nfolds=10, means_only=False):\n",
    "    results = {}\n",
    "    kf = KFold(n_splits=nfolds, shuffle=True, random_state=1111)\n",
    "    for algo_name, algo in algs:\n",
    "        results[algo_name] = []\n",
    "        sum_fold = 0 \n",
    "        number_of_outliers = 0\n",
    "        print(\"\\n\")\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            algo.fit(X_train, y_train)\n",
    "            y_pred = algo.predict(X_test)\n",
    "            results[algo_name].append(accuracy_score(y_test, y_pred))\n",
    "            sum_fold += results[algo_name][-1]\n",
    "            #print(f\"Fold {fold} for {algo_name}: {results[algo_name][-1]}\")\n",
    "            if algo_name == \"AdaBoost Check Outliers 3\":\n",
    "                number_of_outliers += algo.get_number_of_outliers()\n",
    "        \n",
    "        print(f\"Number of outliers identified: {number_of_outliers/nfolds}\")\n",
    "        print(f\"Mean for {algo_name}: {sum_fold/nfolds}\")\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    if not means_only:\n",
    "        return results_df\n",
    "    else:\n",
    "        results_means = {}\n",
    "        for algo_name, algo in algs:\n",
    "            results_means[algo_name] = [np.mean(results[algo_name])]\n",
    "        return pd.DataFrame.from_dict(results_means)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45324b4448f9bb79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cv(results_cv,metric='Accuracy', title=\"Cross-validation results for multiple algorithms in a single task\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(results_cv)\n",
    "    ax.set_xticklabels(results_cv.columns)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb42daccb883591e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c4b740f178410e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from algorithms.adaboost import AdaBoost\n",
    "\n",
    "models = [\n",
    "    (\"AdaBoost ficheiro\", AdaBoost()),\n",
    "    (\"AdaBoost Check Outliers 3\", AdaBoost(check_outliers=True, outlier_threshold=5)),\n",
    "    (\"AdaBoost biblioteca\", AdaBoostClassifier(algorithm='SAMME'))\n",
    "]\n",
    "\n",
    "for id in list_num_dataset_id:\n",
    "    print(f\"\\nDataset {id}:\")\n",
    "    X = dataframes[id].drop(columns=['target'], axis=1)\n",
    "    y = dataframes[id]['target']\n",
    "\n",
    "    results = run_cv(X, y, models, means_only=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cecbc6db8240394c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc98cea3d9027a60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Análise dos outliers de cada dataset \n",
    "'''\n",
    "O valor que você deve colocar no limite depende do que você considera um outlier. No código que você forneceu, você está usando a regra do escore z para detectar outliers. Especificamente, você está considerando qualquer valor que seja mais de 3 desvios padrão da média como um outlier.  \n",
    "\n",
    "O valor de 3 é comumente usado na regra do escore z porque corresponde a um nível de confiança de cerca de 99,7% em uma distribuição normal. Isso significa que, em uma distribuição normal, esperamos que cerca de 99,7% dos valores estejam dentro de 3 desvios padrão da média.\n",
    "\n",
    "'''\n",
    "\n",
    "def showoutliers(ids, show_Boxplot = True):\n",
    "\n",
    "    limite = 5\n",
    "\n",
    "    df_1 = dataframes[id][dataframes[id]['target'] == 1]\n",
    "    df_1 = df_1.drop(columns=['target'], axis=1)\n",
    "    df_not_1 = dataframes[id][dataframes[id]['target'] == -1]\n",
    "    df_not_1 = df_not_1.drop(columns=['target'], axis=1)\n",
    "\n",
    "    outliers_1 = set()\n",
    "    outliers_not_1 = set()\n",
    "\n",
    "    for coluna in df_1.columns:\n",
    "\n",
    "        data_plot_1 = df_1[coluna]\n",
    "        data_plot_not_1 = df_not_1[coluna]\n",
    "\n",
    "        if show_Boxplot:\n",
    "            print(f'Outliers em {coluna}:')\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "            # Plot para a classe 1\n",
    "            axs[0].boxplot(df_1[f'{coluna}'], vert=False)\n",
    "            axs[0].set_title('Boxplot para df_1')\n",
    "\n",
    "            # Plot para a classe -1\n",
    "            axs[1].boxplot(df_not_1[f'{coluna}'], vert=False)\n",
    "            axs[1].set_title('Boxplot para df_not_1')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        z_scores_1 = np.abs((data_plot_1 - data_plot_1.mean()) / data_plot_1.std())\n",
    "        outliers_1.update(data_plot_1[z_scores_1 > limite].index)\n",
    "        #print(f\"outliers 1: {outliers_1}\")\n",
    "\n",
    "        z_scores_not_1 = np.abs((data_plot_not_1 - data_plot_not_1.mean()) / data_plot_not_1.std())\n",
    "        outliers_not_1.update(data_plot_not_1[z_scores_not_1 > limite].index)\n",
    "        #print(f\"outliers -1: {outliers_not_1}\")\n",
    "\n",
    "    n_outliers = len(outliers_1) + len(outliers_not_1)\n",
    "    return n_outliers\n",
    "\n",
    "\n",
    "'''\n",
    "Quando estamos a analisar os outliers fará sentido separar as classes (ver o boxplot para cada classe separadamente) ou é melhor analisar todas as classes juntas?\n",
    "A análise de outliers deve ser feita para cada classe separadamente. Se você analisar todas as classes juntas,\n",
    " você pode acabar considerando valores que são normais para uma classe como outliers, simplesmente porque eles são incomuns em relação a outra classe.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37be90663c86114e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for id in list_num_dataset_id:\n",
    "    n_outliers = showoutliers(id, show_Boxplot=False)\n",
    "    print(f\"\\nDataset {id}:\")\n",
    "    print(f'Número de outliers: {n_outliers}')\n",
    "    print(f'Número de entradas: {len(dataframes[id])}')\n",
    "    #show % of outliers in the dataset\n",
    "    percentage_outliers = n_outliers/(len(dataframes[id]))\n",
    "    print(f'Percentagem de outliers: {percentage_outliers*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7bdba0b1be9f39b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T00:59:57.085088Z",
     "start_time": "2024-05-18T00:59:57.071751Z"
    }
   },
   "id": "f6ca06326ad95c5a",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
